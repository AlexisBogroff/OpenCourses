{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<h1><center><span style=\"color:#3775a8\"><u>SORBONNE DATA ANALYTIC : Data Cleaning</u></span></center></h1>**\n",
    "# **<span style=\"color:#3775a8\">Découverte de Pandas</span>**\n",
    "\n",
    "**Bienvenue dans ce module !**\n",
    "\n",
    "Pandas est l'un des packages les plus utilisées pour la manipulation de données en Python bien qu'il en existe d'autres (ex: datatable, vaex, ...).\n",
    "\n",
    "Comme vous l'avez vu dans la vidéo, le data cleaning est la clé pour réussir une analyse et/ou une modélisation prédictive. Voir l'ensemble des fonctions de pandas serait totalement inutile. Le plus important est de comprendre le fonctionnement du package et de savoir ce que l'on souhaite faire pour ensuite aller chercher l'information qui y réfère dans la documentation.\n",
    "De plus, je vous conseille de ne jamais utiliser une fonction sans regarder en amont les paramètres de la fonction.\n",
    "\n",
    "Vous allez voir dans cette formation comment utiliser pandas pour **nettoyer vos données** de manière à les rendre modélisables.\n",
    "\n",
    "Avant toutes choses, voici les packages et les versions que j'utilise: \n",
    "- numpy==1.19.1\n",
    "- pandas==1.1.0\n",
    "\n",
    "**Attention**, si vous n'avez pas strictement les même, il est possible que vos output ne soient pas exactement les mêmes !\n",
    "\n",
    "## **<span style=\"color:#3775a8\">0. Importer les packages</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path_data = '~/Mettez/Votre/Chemin/Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#3775a8\">1. Suppression des variables sans dictionnaire de données et/ou que vous ne comprenez pas</span>**\n",
    "\n",
    "L'objectif sera de nettoyer la base de donnée afin de pouvoir prédire la Region en fonction des différents éléments naturels.\n",
    "\n",
    "Voici les données que nvus allez utiliser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_data + 'base.csv')\n",
    "df.sample(n=10, random_state=893717398)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dictionnaire:**\n",
    "- Date: Date de la mesure\n",
    "- Vitesse_Vent_Moyen_10min: Vitesse moyenne du vent\n",
    "- Humidité: Pourcentage d'humidité\n",
    "- Precipitation_derniere_heure: \n",
    "- Nom: Ville\n",
    "- Temperature_dC: Température en degrés Celsius\n",
    "- Altitude: Altitude de la ville\n",
    "- Longitude: Longitude\n",
    "- Latitude: Latitude\n",
    "- Region : Region\n",
    "- Mois: Moi de l'année 1: Janvier à 12: Décembre\n",
    "\n",
    "Ici, nous n'avons pas d'information sur la variable **Precipitation_derniere_heure** et imaginons que personne ne sache ce à quoi elle réfère, vous pouvez la supprimer.\n",
    "De plus, l'**Altitude**, la **Longitude** et la **Latitude** sont **hors périmètre** car ce ne sont pas des éléments naturels.\n",
    "De plus, le **Mois** peut être obtenu directement à partir de la date donc nous allons le supprimer pour cet exercice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop_without_dictionnary = ['Precipitation_derniere_heure', 'Altitude', 'Longitude', 'Latitude', 'Mois']\n",
    "df.drop(columns=cols_to_drop_without_dictionnary, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#3775a8\">2. Parser les dates</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ici, seule la variable Date est une date\n",
    "print(\"Format de la date avant d'être parser: \" + str(df['Date'].dtypes))\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'], format=\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "print(\"\\nFormat de la date après d'être parser: \"+str(df['Date'].dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#3775a8\">3. Splitter la base de données 1/2</span>**\n",
    "\n",
    "Vous allez utiliser les données de 2011 à 2017 pour l'entrainement du modèle et les données de 2018 à 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['Date'] < '2018-01-01 00:00:00']\n",
    "test = df[df['Date'] >= '2018-01-01 00:00:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#3775a8\">4. Hypothèse d’indépendance des observations et traitement des doublons</span>**\n",
    "\n",
    "Cette base de données a été construite en input pour garder uniquement 8 villes afin de ne pas être trop lourde en terme de Mb.\n",
    "Selon la méthodologie du data cleaning, vous devriez avoir une ligne pour par ville afin de pouvoir modéliser. Mais 8 villes n'est pas suffisant.\n",
    "Donc vous allez considérer pour la suite du notebook que toutes les observations sont indépendantes les unes des autres.\n",
    "\n",
    "Cependant, un bon exercice pour pratiquer ce point 3 serait d'utiliser la stratégie 4 en créant les variables suivantes:\n",
    "- Vitesse_Vent_Moyen_10min_Semestre1\n",
    "- Vitesse_Vent_Moyen_10min_Semestre2\n",
    "- Humidite_Semestre1\n",
    "- Humidite_Semestre2\n",
    "- Temperature_dC_Semestre1\n",
    "- Temperature_dC_Semestre2\n",
    "Agrégées par la valeur **médiane**.\n",
    "Vous aurez alors 8 observations pour chaque Nom et 6 variables.\n",
    "\n",
    "\n",
    "Pour la suite du notebook, je considère que toutes les obsevations sont indépendantes et je supprime le **Nom**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['Nom'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#3775a8\">5. Splitter la base de données 2/2</span>**\n",
    "Cette fois-ci, vous allez splitter aléatoirement votre base de train en 2 avec un ratio de 60-40:\n",
    "- train: 60%\n",
    "- validation: 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = train.sample(frac=0.4,random_state=893717398)\n",
    "train=train.drop(validation.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#3775a8\">6. Supprimer les constantes</span>**\n",
    "Un simple head permet de voir tout de suite qu'aucune variable n'est constante.\n",
    "\n",
    "Essayez de créer une boucle ou une fonction qui déterminerait le nombre de valeurs uniques pour chaque variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(n=10, random_state=893717398)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#3775a8\">7. Gestion des valeurs manquantes</span>**\n",
    "Voir les valeurs manquantes en nombre et en pourcentage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train.columns:\n",
    "    print('Nombre de valeurs manquantes pour la variable '+str(i)+' : '+str(train[i].isna().sum()))\n",
    "    \n",
    "for i in train.columns:\n",
    "    print('Pourcentage de valeurs manquantes pour la variable '+str(i)+' : '+str(round((train[i].isna().sum())*100/len(train),2))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous l'objectif est de modéliser la région en fonction des variables d'éléments naturels.\n",
    "Compte tenu que Region est votre target et non une variable explicative comme le sont Date, Vitesse_Vent_Moyen_10min, Humidite et Temperature_dC; et que l'on ne sait pas à quelle région correspond une observation manquante, il est possible de supprimer les observations.\n",
    "\n",
    "Pour ce qui est des autres cas, compte tenu que le pourcentage est très bas, vous pouvez procéder à une simple imputation par la médiane.\n",
    "\n",
    "Un bon exercice afin de pratiquer la manipulation de données ainsi que la data visualization que vous verrez au prochain cours serait de trouver une valeur plus probable que la médiane, bien que cela ne changerait pas fondamentalement les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(subset=['Region'], axis=0, inplace=True)\n",
    "\n",
    "vent_median=train['Vitesse_Vent_Moyen_10min'].median()\n",
    "humidite_median=train['Humidite'].median()\n",
    "temperature_median=train['Temperature_dC'].median()\n",
    "\n",
    "train['Vitesse_Vent_Moyen_10min'].fillna(vent_median, inplace=True)\n",
    "train['Humidite'].fillna(humidite_median, inplace=True)\n",
    "train['Temperature_dC'].fillna(temperature_median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train.columns:\n",
    "    print('Nombre de valeurs manquantes pour la variable '+str(i)+' : '+str(train[i].isna().sum()))\n",
    "    \n",
    "for i in train.columns:\n",
    "    print('Pourcentage de valeurs manquantes pour la variable '+str(i)+' : '+str(round((train[i].isna().sum())*100/len(train),2))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#3775a8\">8. Analyse descriptive des variables et outliers</span>**\n",
    "Vous verrez dans le cours consacré à la Data Visualization comment en faire en python grâce au package matplotlib. En attendant, voici une méthode très simple permettant d'avoir une vue facile sur la présence d'outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#3775a8\">9. Valider le type des variables</span>**\n",
    "Extraire et verifier que le type de variable correspond à ce que vous voulez vous permettra de faire des sanity check notament au moment de l'application de votre modèle ainsi que pour confirmer qu'une transformation fait le rendu souhaité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#3775a8\">10. Cas des variables corrélées</span>**\n",
    "Ici, vous avez 3 variables conitnues donc 9 paires possibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Vitesse_Vent_Moyen_10min', 'Humidite', 'Temperature_dC']].corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, aucune variables ne sont trop corrélées entre elles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#3775a8\">11. Encoding des variables catégorielles en numériques</span>**\n",
    "Ici, vous n'avez pas de variables catégorielles donc cette étape n'est pas utile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#3775a8\">12. Appliquer les transformations sur Validation & Test</span>**\n",
    "Il faut récupérer toutes les étapes afin que l'algorithme prédictif qui sera entrainé sur le train soit applicable dans les mêmes conditions sur la validation et le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=['Nom'], axis=1, inplace=True)\n",
    "validation.dropna(subset=['Region'], axis=0, inplace=True)\n",
    "test.dropna(subset=['Region'], axis=0, inplace=True)\n",
    "\n",
    "validation['Vitesse_Vent_Moyen_10min'].fillna(vent_median, inplace=True)\n",
    "validation['Humidite'].fillna(humidite_median, inplace=True)\n",
    "validation['Temperature_dC'].fillna(temperature_median, inplace=True)\n",
    "\n",
    "test['Vitesse_Vent_Moyen_10min'].fillna(vent_median, inplace=True)\n",
    "test['Humidite'].fillna(humidite_median, inplace=True)\n",
    "test['Temperature_dC'].fillna(temperature_median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des données pour le features engineering:\n",
    "train.to_csv(path_data + 'train.csv', index=False)\n",
    "validation.to_csv(path_data + 'validation.csv', index=False)\n",
    "test.to_csv(path_data + 'test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A présent, votre base est prête à être modélisée. Vous avez pu voir au travers de toutes les étapes comment nettoyer une base de donnée avec pandas. Comme vous l'avez également vu, il aurait été possible de faire différentes actions que je vous laisse faire de vous même afin de vous exercer.\n",
    "\n",
    "Vous allez voir dans le prochain notebook consacré au features engineering que vous auriez pu créer encore davantage de variables que les 3 finales que sont la vitesse du vent, l'humidité et la température en °C.\n",
    "\n",
    "# **<span style=\"color:#37a871\">Félicitations !</span>**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
